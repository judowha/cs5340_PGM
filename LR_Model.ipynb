{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1qUWY2EBvQZrBqgCedGk6XWrKSsPFMBvw","timestamp":1713069418917}],"authorship_tag":"ABX9TyPk8AN4SeCTy9FN0vtEZiUT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n","from sklearn.linear_model import LogisticRegression\n","from imblearn.over_sampling import SMOTE\n","from sklearn.feature_selection import SelectKBest, f_classif\n","\n","def train_logistic_regression():\n","    print(\"Training with logistic regression\")\n","    data_df = pd.read_csv('/content/drive/My Drive/preprocessed_data.csv')\n","    used_features = [\"AMT_INCOME_TOTAL\", \"NAME_EDUCATION_TYPE\", \"FLAG_OWN_REALTY\", \"DAYS_EMPLOYED\", \"CNT_CHILDREN\",\n","                     \"NAME_HOUSING_TYPE\", \"FLAG_OWN_CAR\", \"DAYS_BIRTH\", \"GOOD_REPUTATION\"]\n","    data_df = data_df[used_features]\n","\n","    # Split data into features and target variable\n","    X = data_df.drop('GOOD_REPUTATION', axis=1)\n","    y = data_df['GOOD_REPUTATION']\n","\n","    # Feature Scaling\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X)\n","\n","    # Polynomial Features\n","    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n","    X_poly = poly.fit_transform(X_scaled)\n","\n","    # Feature Selection\n","    selector = SelectKBest(f_classif, k=8)\n","    X_selected = selector.fit_transform(X_poly, y)\n","\n","    # Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n","\n","    # Apply SMOTE to the training data for oversampling\n","    smote = SMOTE(random_state=42)\n","    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n","\n","    # Initialize and train the logistic regression model with class weight\n","    model = LogisticRegression(max_iter=300, solver='liblinear', penalty='l2', C=0.1)\n","    model.fit(X_train_smote, y_train_smote)\n","\n","    # Make predictions\n","    predictions = model.predict(X_test)\n","\n","    # Evaluate the model\n","    accuracy = accuracy_score(y_test, predictions)\n","    conf_matrix = confusion_matrix(y_test, predictions)\n","    f1 = f1_score(y_test, predictions)\n","\n","    print(\"Accuracy:\", accuracy)\n","    print(\"Confusion Matrix:\")\n","    print(conf_matrix)\n","    print(f\"f1: {f1}\")\n","\n","if __name__ == \"__main__\":\n","    train_logistic_regression()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gl-Mw26hH7Wf","executionInfo":{"status":"ok","timestamp":1713006169200,"user_tz":-480,"elapsed":6,"user":{"displayName":"Jamal Ahamed","userId":"07281032733569561465"}},"outputId":"90048a04-1171-4cf2-9629-9593b6940cb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training with logistic regression\n","Accuracy: 0.5670597915523862\n","Confusion Matrix:\n","[[ 440  432]\n"," [2725 3695]]\n","f1: 0.7006731772067887\n"]}]}]}